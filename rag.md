### 大模型
- 局限性
    - 时效性
    - 企业数据依赖
- 解决方案
    - RAG
    - fine-tuning(微调)
    - 增量训练

### RAG(检索增强生成)
- 通过引入外部知识库的检索机制,提升生成内容的准确性、相关性和时效性

- 步骤
    - 构建数据索引(Index)
        - 加载不同数据源
        - 将文档分割成块
        - 对块的数据进行向量化并存储到向量数据库
    - 检索增强
        - 通过向量相似度检索与问题最想关的K个文档
        - 检索召回知识附加上下文填充至Prompt
    - 生成


- 文档检索小助手
- doctran
- chatdoc
    - 可以加载PDF或者xls格式文档
    - 可以对文档进行适当切分
    - 使用openai进行向量化
    - 使用chomadb实现本地向量存储
    - 使用智能检索实现和文档的对话

#### 检索优化的方式
- 使用多重查询提高文档检索精确度(MultiQueryRetriever)
- 使用上下文压缩检索降低冗余信息(LLMChainExtractor)
- 在向量存储中使用最大边际相似性(MMR)和相似性打分检索来提高精度


#### 项目

- 银行AI Chatbot智能客服

- 基于AI的CSV数据分析处理
    - CSV数据处理的多种方式: DF, SQL
    - 输入分析及参数提取
    - 基于Code Agent的代码生成和执行
    - 数据可视化实现

- 智能知识库问答
- 说一下RAG有哪几个步骤?
- 实际RAG项目中，用过哪些优化技巧?
- 说一下RAG一般怎么做效果评估？ 
- 为什么RAG中会出现幻觉？如何解决？ 
- 实际项目中遇到的各种边界case，你们是怎么解决的？
- 文本分割的粒度
    - 粒度太大可能导致检索不精准, 粒度太小可能会导致信息不全面
    - 问题的答案可能跨越多个块，需要将答案切分到多个块

#### RAG的流程
- 离线步骤
  - 文档加载
  - 文档切分
  - 向量化
  - 灌入向量库
- 在线步骤
    - 获得问题
    - 用户问题向量化
    - 检索向量数据库
    - 将检索结果和用户问题填入prompt模板
    - 用最终获得的prompt调用LLM
    - 生成回复

用了一个开源的RAG，感觉效果挺好，但是对于中文的模型效果不太好，而且对于中文的模型，需要自己训练，
所以还是自己训练一个模型比较好。
- 检查预处理效果
- 测试检索效果
- 测试大模型能力
